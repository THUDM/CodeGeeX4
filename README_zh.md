![](resources/logo.jpeg)

<p align="center">
    ğŸ  <a href="https://codegeex.cn" target="_blank">Homepage</a>ï½œğŸ›  Extensions <a href="https://marketplace.visualstudio.com/items?itemName=aminer.codegeex" target="_blank">VS Code</a>, <a href="https://plugins.jetbrains.com/plugin/20587-codegeex" target="_blank">Jetbrains</a>ï½œğŸ¤— <a href="https://huggingface.co/THUDM/codegeex4-all-9b" target="_blank">HF Repo</a> | ğŸª§ <a href="https://huggingface.co/spaces/THUDM/CodeGeeX" target="_blank">HF DEMO</a>
</p>

[English](./README.md) | [ä¸­æ–‡](./README_zh.md)

# CodeGeeX4: å¼€æºå¤šè¯­è¨€ä»£ç ç”Ÿæˆæ¨¡å‹

æˆ‘ä»¬æ¨å‡ºäº† CodeGeeX4-ALL-9Bï¼Œè¿™æ˜¯æœ€æ–°çš„ CodeGeeX4 ç³»åˆ—æ¨¡å‹çš„å¼€æºç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹æ˜¯åœ¨ [GLM-4-9B](https://github.com/THUDM/GLM-4) åŸºç¡€ä¸ŠæŒç»­è®­ç»ƒçš„å¤šè¯­è¨€ä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚ä½¿ç”¨å•ä¸ª CodeGeeX4-ALL-9B æ¨¡å‹ï¼Œå¯ä»¥æ”¯æŒä»£ç è¡¥å…¨ä¸ç”Ÿæˆã€ä»£ç è§£é‡Šã€è”ç½‘æœç´¢ã€å‡½æ•°è°ƒç”¨ã€ä»“åº“çº§ä»£ç é—®ç­”ç­‰å¤šç§åŠŸèƒ½ï¼Œè¦†ç›–äº†è½¯ä»¶å¼€å‘çš„å„ä¸ªåœºæ™¯ã€‚CodeGeeX4-ALL-9B åœ¨ [BigCodeBench](https://huggingface.co/datasets/bigcode/bigcodebench) å’Œ [NaturalCodeBench](https://github.com/THUDM/NaturalCodeBench) ç­‰å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æå…·ç«äº‰åŠ›çš„è¡¨ç°ã€‚å®ƒæ˜¯ç›®å‰å‚æ•°é‡å°‘äº 100 äº¿çš„æœ€å¼ºä»£ç ç”Ÿæˆæ¨¡å‹ï¼Œç”šè‡³è¶…è¶Šäº†æ›´å¤§çš„é€šç”¨æ¨¡å‹ï¼Œåœ¨æ¨ç†é€Ÿåº¦å’Œæ¨¡å‹æ€§èƒ½æ–¹é¢è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚

## æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹             | ç±»å‹ | ä¸Šä¸‹æ–‡é•¿åº¦ | ä¸‹è½½åœ°å€                                                                                                                                                                                                    |
|-------------------|------|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| codegeex4-all-9b  | Chat | 128K       | [ğŸ¤— Huggingface](https://huggingface.co/THUDM/codegeex4-all-9b) [ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/codegeex4-all-9b) [ğŸŸ£ WiseModel](https://wisemodel.cn/models/ZhipuAI/codegeex4-all-9b)    |

## å¿«é€Ÿå¼€å§‹

è¯·ä½¿ç”¨ `4.39.0<=transformers<=4.40.2` éƒ¨ç½² [codegeex4-all-9b](https://huggingface.co/THUDM/codegeex4-all-9b)ï¼š

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

device = "cuda" if torch.cuda.is_available() else "cpu"
tokenizer = AutoTokenizer.from_pretrained("THUDM/codegeex4-all-9b", trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    "THUDM/codegeex4-all-9b",
    torch_dtype=torch.bfloat16,
    low_cpu_mem_usage=True,
    trust_remote_code=True
).to(device).eval()
inputs = tokenizer.apply_chat_template([{"role": "user", "content": "write a quick sort"}], add_generation_prompt=True, tokenize=True, return_tensors="pt", return_dict=True).to(device)
with torch.no_grad():
    outputs = model.generate(**inputs)
    outputs = outputs[:, inputs['input_ids'].shape[1]:]
    print(tokenizer.decode(outputs[0], skip_special_tokens=True))
```
ä½¿ç”¨ `vllm==0.5.1` å¿«é€Ÿå¯åŠ¨ [codegeex4-all-9b](https://huggingface.co/THUDM/codegeex4-all-9b)ï¼š

```python
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

# CodeGeeX4-ALL-9B
# max_model_len, tp_size = 1048576, 4
# å¦‚æœå‡ºç°å†…å­˜ä¸è¶³ï¼ˆOOMï¼‰ï¼Œå‡å°‘max_model_lenï¼Œæˆ–å¢åŠ tp_size
max_model_len, tp_size = 131072, 1
model_name = "codegeex4-all-9b"
prompt = [{"role": "user", "content": "Hello"}]

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
llm = LLM(
    model=model_name,
    tensor_parallel_size=tp_size,
    max_model_len=max_model_len,
    trust_remote_code=True,
    enforce_eager=True,
    # å¦‚æœå‡ºç°OOMï¼Œå°è¯•ä½¿ç”¨ä»¥ä¸‹å‚æ•°
    # enable_chunked_prefill=True,
    # max_num_batched_tokens=8192
)
stop_token_ids = [151329, 151336, 151338]
sampling_params = SamplingParams(temperature=0.95, max_tokens=1024, stop_token_ids=stop_token_ids)

inputs = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)
outputs = llm.generate(prompts=inputs, sampling_params=sampling_params)

print(outputs[0].outputs[0].text)
```

é€šè¿‡ vllm è®¾ç½® OpenAI å…¼å®¹æœåŠ¡ï¼Œè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹ [OpenAI å…¼å®¹æœåŠ¡å™¨](https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html)ï¼š

```bash
python -m vllm.entrypoints.openai.api_server \
     --model THUDM/codegeex4-all-9b \
     --trust_remote_code
```

## ç”¨æˆ·æŒ‡å—
æˆ‘ä»¬ä¸º CodeGeeX4-ALL-9B æä¾›äº†ç”¨æˆ·æŒ‡å—ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿäº†è§£å’Œä½¿ç”¨è¯¥æ¨¡å‹ï¼š

![ALL Fuctions](./resources/all_functions.jpg)

1. **[ç³»ç»Ÿæç¤ºæŒ‡å—](./guides/System_prompt_guideline_zh.md)**ï¼šæœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•åœ¨ CodeGeeX4-ALL-9B ä¸­ä½¿ç”¨ç³»ç»Ÿæç¤ºï¼ŒåŒ…æ‹¬ VSCode æ’ä»¶çš„å®˜æ–¹ç³»ç»Ÿæç¤ºã€è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºä»¥åŠç»´æŠ¤å¤šè½®å¯¹è¯å†å²çš„ä¸€äº›æŠ€å·§ã€‚

2. **[ä¸Šä¸‹æ–‡è¡¥å…¨æŒ‡å—](./guides/Infilling_guideline_zh.md)**ï¼šæœ¬æŒ‡å—è§£é‡Šäº† VSCode æ’ä»¶çš„å®˜æ–¹å¡«å……æ ¼å¼ï¼Œæ¶µç›–ä¸€èˆ¬è¡¥å…¨ã€è·¨æ–‡ä»¶è¡¥å…¨å’Œåœ¨ä»“åº“ä¸­ç”Ÿæˆæ–°æ–‡ä»¶ã€‚

3. **[é¡¹ç›®çº§ä»£ç ç”ŸæˆæŒ‡å—](./guides/Repository_tasks_guideline_zh.md)**ï¼šæœ¬æŒ‡å—å±•ç¤ºäº†å¦‚ä½•åœ¨ CodeGeeX4-ALL-9B ä¸­ä½¿ç”¨é¡¹ç›®çº§ä»»åŠ¡ï¼ŒåŒ…æ‹¬é¡¹ç›®çº§åˆ«çš„é—®ç­”ä»»åŠ¡ï¼Œä»¥åŠå¦‚ä½•è§¦å‘ CodeGeeX4-ALL-9B çš„ aicommiter åŠŸèƒ½ä»¥æ‰§è¡Œä»“åº“çº§åˆ«ä»»åŠ¡ä¸­çš„åˆ é™¤ã€æ·»åŠ å’Œæ›´æ”¹æ–‡ä»¶æ“ä½œã€‚

è¿™äº›æŒ‡å—æ—¨åœ¨å¸®åŠ©å¤§å®¶å…¨é¢ç†è§£æ¨¡å‹çš„ç”¨æ³•å¹¶æ›´å¥½å‘æŒ¥æ¨¡å‹çš„èƒ½åŠ›ã€‚

## è¯„æµ‹æŒ‡æ ‡

CodeGeeX4-ALL-9B è¢«è¯„ä¸ºå‚æ•°é‡100 äº¿å†…çš„æœ€å¼ºæ¨¡å‹ï¼Œç”šè‡³è¶…è¶Šäº†å‚æ•°é‡å¤§å‡ å€çš„é€šç”¨æ¨¡å‹ï¼Œåœ¨æ¨ç†æ€§èƒ½å’Œæ¨¡å‹èƒ½åŠ›ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³æ•ˆæœã€‚

| **æ¨¡å‹**                   | **åºåˆ—é•¿åº¦** | **HumanEval** | **MBPP** | **NCB** | **LCB** | **HumanEvalFIM** | **CRUXEval-O** |
|-----------------------------|----------------|---------------|----------|---------|---------|------------------|----------------|
| Llama3-70B-intruct          | 8K             | 77.4          | 82.3     | 37.0    | 27.4    | -                | -              |
| DeepSeek Coder 33B Instruct | 16K            | 81.1          | 80.4     | 39.3    | 29.3    | 78.2             | 49.9           |
| Codestral-22B               | 32K            | 81.1          | 78.2     | 46.0    | 35.3    | 91.6             | 51.3           |
| CodeGeeX4-All-9B            | 128K           | 82.3          | 75.7     | 40.4    | 28.5    | 85.0             | 47.1           |

åœ¨ BigCodeBench çš„ complete å’Œ instruct ä»»åŠ¡ä¸­ï¼ŒCodeGeeX4-ALL-9B åˆ†åˆ«å–å¾—äº† `48.9` å’Œ `40.4` çš„é«˜åˆ†ï¼Œè¿™åœ¨å‚æ•°é‡ 200 äº¿å†…çš„æ¨¡å‹ä¸­æ˜¯æœ€é«˜çš„åˆ†æ•°ã€‚
![BigCodeBench Test Results](./metric/pics/Bigcodebench.png)
Crux-Eval æ˜¯æµ‹è¯•ä»£ç æ¨ç†ã€ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ï¼Œå€ŸåŠ©äºå…¶å¼ºå¤§çš„ COT èƒ½åŠ›ï¼ŒCodeGeeX4-ALL-9B å±•ç°å‡ºè‰²çš„è¡¨ç°ã€‚åœ¨ HumanEvalã€MBPP å’Œ NaturalCodeBench ç­‰ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒCodeGeeX4-ALL-9B ä¹Ÿå–å¾—äº†å‡ºè‰²çš„æˆç»©ã€‚ç›®å‰ï¼Œå®ƒæ˜¯å”¯ä¸€æ”¯æŒ Function Call åŠŸèƒ½çš„ä»£ç æ¨¡å‹ï¼Œç”šè‡³å–å¾—äº†æ¯” GPT-4 æ›´é«˜çš„åˆ†æ•°ã€‚
![Function Call Evaluation](./metric/pics/FunctionCall.png)
æ­¤å¤–ï¼Œåœ¨â€œCode Needle In A Haystackâ€ (NIAH) è¯„ä¼°ä¸­ï¼ŒCodeGeeX4-ALL-9B æ¨¡å‹å±•ç¤ºäº†åœ¨ 128K èŒƒå›´å†…æ£€ç´¢ä»£ç çš„èƒ½åŠ›ï¼Œåœ¨pythonè¯­è¨€ç¯å¢ƒè¾¾åˆ°äº† 100% çš„æ£€ç´¢å‡†ç¡®ç‡ï¼Œå¹¶åœ¨è·¨æ–‡ä»¶è¡¥å…¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚
<p align="center">
  <img src=./metric/pics/NIAH_PYTHON.png alt="å›¾ç‰‡1æè¿°" width="45%">
  <img src="./metric/pics/NIAH_ALL.png" alt="å›¾ç‰‡2æè¿°" width="45%">
</p>

æ›´è¯¦ç»†çš„è¯„ä¼°ç»“æœè¯·çœ‹ **[è¯„ä¼°ç»“æœ](./metric/README_zh.md)** ã€‚


## è®¸å¯è¯

æœ¬ä»“åº“ä¸­çš„ä»£ç æ˜¯æ ¹æ® [Apache-2.0](https://www.apache.org/licenses/LICENSE-2.0) è®¸å¯è¯å¼€æºçš„ã€‚æ¨¡å‹æƒé‡æ ¹æ® [æ¨¡å‹è®¸å¯è¯](MODEL_LICENSE) è®¸å¯ã€‚CodeGeeX4-9B æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å¼€æ”¾ã€‚å¯¹äºå¸Œæœ›å°†æ¨¡å‹ç”¨äºå•†ä¸šç›®çš„çš„ç”¨æˆ·ï¼Œè¯·å¡«å†™ [ç™»è®°è¡¨](https://bigmodel.cn/mla/form?mcode=CodeGeeX4-ALL-9B)ã€‚


## å¼•ç”¨

å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@inproceedings{zheng2023codegeex,
      title={CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X},
      author={Qinkai Zheng and Xiao Xia and Xu Zou and Yuxiao Dong and Shan Wang and Yufei Xue and Zihan Wang and Lei Shen and Andi Wang and Yang Li and Teng Su and Zhilin Yang and Jie Tang},
      booktitle={KDD},
      year={2023}
}
```
